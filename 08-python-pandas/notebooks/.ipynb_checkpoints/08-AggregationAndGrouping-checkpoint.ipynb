{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Functions and Group Statistics\n",
    "* Contact: Lachlan Deer, [econgit] @ldeer, [github/twitter] @lachlandeer\n",
    "\n",
    "So far our work with Pandas as been purely about simple transformations of each row or data; whether selecting them or creating new columns out of old ones. This is rarely enough - we typically want some degree of summarization of the data; either of an entire column; or on parts of (groups) of the column in question.\n",
    "\n",
    "This is what we will go after here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('out_data/state_labour_statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Aggregation\n",
    "\n",
    "Like NumPy, Pandas has some of the standard data aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234567890)\n",
    "series = pd.Series(rng.rand(5))\n",
    "series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.mean(), series.median(), series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a data-frame; these aggregations return results for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want the aggregation across a row, you can specify thats what you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times, we want to see all of the common aggregates at once. Pandas provides a function `.describe()` to do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful aggregation functions in pandas are in the table below:\n",
    "\n",
    "[insert table]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst these aggregations can provide some notions of patterns in the data - often we want to go deeper - and compute these summaries at the level of a group (like a state of a year). Pandas has the `groupby` function that will allow us to efficiently looks at aggregate statistics on subsets of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy: The Split, Apply, Combine Paradigm\n",
    "The canonical example of the groupby paradigm  is best represented in a figure:\n",
    "\n",
    "[insert figure]\n",
    "\n",
    "In words, GroupBy does the following:\n",
    "* The *split* step breaks up a DataFrame into subsets depending on the value of a specified key\n",
    "* the *apply* step computes some aggregate functions within an individual group\n",
    "* The *combine* step merges the results of the computations within groups back to a single dataset\n",
    "\n",
    "We could certainly perform all these operations by ourselves, manually - but the tedium of the task combined with a high probability of error makes us immediately want to use a built in function that abstracts away from individual steps and asks the user to rather think of the operation as a whole rather than the individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a start - let's look at the average unemployment rate by state. As a first step we must specify the name of the column we are looking to split on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of this object as an under the hood view of a `DataFrame`. Note that it does not compute anything until an aggregation is applied to it; i.e. it uses 'lazy evaluation'\n",
    "\n",
    "Now lets get those mena unemployment rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state').unemployment_rate.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice if we wanted the aggregation function to be applied to all of the columns, we can skip the part where we specify the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if we want multiple, but not all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state')['unemployment_rate', 'qty_unemployed'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very Cool!\n",
    "\n",
    "## Challenge\n",
    "\n",
    "Try and compute statistics where the grouping is described by multiple variables:\n",
    "1. Compute the average unemployment rate by state-year\n",
    "2. Compute the average unemployment rate by state-year-month\n",
    "3. Compute the average unemployment rate by state-year for the Carolinas (Hint: use the .filter() function after the computation)\n",
    "4. Compute the average unemployment rate by state-year and use `unstack` to view the data in a way that is different from the default output\n",
    "\n",
    "#### Partial Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['state', 'year'])['unemployment_rate'].mean().filter(like='Carolina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['state', 'year'])['unemployment_rate'].mean().unstack(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More useful GroupBy functionality\n",
    "\n",
    "Often we want more than one aggregate statistic, for example we may want the min, mean and max by State. We can use the `.aggregate()` function to get these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state')['unemployment_rate'].aggregate([np.min, np.mean, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dress it up a little too if we like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('state')['unemployment_rate'] \\\n",
    "        .aggregate({'Min. Unemploy.' : np.min,\n",
    "                    'Mean Unemploy.' : np.mean,\n",
    "                    'Max. Unemploy.' : np.max})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the challenge above, we used filter to select out states based on a string, but there are more uses of filter than this simple one. For example, we can filter based on the group properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['unemployment_rate'].min() > 5\n",
    "\n",
    "problem_states = data.groupby('state').filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_states.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_states.groupby(['state', 'year']).unemployment_rate.mean().unstack(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful functions:\n",
    "\n",
    "GroupBy also works alongside the following functions:\n",
    "* `transform()`\n",
    "* `apply()`\n",
    "\n",
    "For lack of time we leave these for you to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
