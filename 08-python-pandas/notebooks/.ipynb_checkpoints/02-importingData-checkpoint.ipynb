{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing (and Exporting) Data\n",
    "* Contact: Lachlan Deer, [econgit] @ldeer, [github/twitter]: @lachlandeer\n",
    "\n",
    "In our early adventures we have focussed on attributes of pandas objects, and created small data sets on the fly. This is rarely how empirical work happens - usually we have some data stored on our computer / in the cloud that we want to load in, work with and then potentially save the results.\n",
    "\n",
    "Pandas has functionality to read and write from/to many different formats. A complete list is available here: http://pandas.pydata.org/pandas-docs/version/0.20/io.html. For economists, we are typically interested in working with:\n",
    "\n",
    "* Csv files: read_csv(), write_csv()\n",
    "* Stata Files: read_stata(), write_stata()\n",
    "* Excel files: read_excel(), write_excel()\n",
    "\n",
    "and possibly working with `sql` or `sas` data too.\n",
    "\n",
    "Hopefully this course has emphasized flat files, that are not encrypted to a particular language are a preferred go-to - so we focus on the csv file functions. Exceptions to this rule are OK if your data is 'big' when you might have to look at sql, or HDF5 or Google Big Query structures, but we are getting way ahead of ourselves.\n",
    "\n",
    "Most functions work similar enough that focussing on csv based read/write operations should be almost without loss of generality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data with `read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our github repository comes with a lot of data in it that we will want to use throughout the session. Let's look at one subdirectory that stores a bunch of data from the BLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glob.glob(\"data/bls-employment-state/*.csv\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and what does a particular file look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/bls-employment-state/LAUST010000000000005.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in that file to our session using `read_csv`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Simplest Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it worked. What is the type of object we just imported?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the future, we may not want to look at such a big excerpt of data - useful functions are then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selectively importing columns\n",
    "\n",
    "Suppose we didn't want to import the `footnotes` column. Pandas allows us to specify the columns we want imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                usecols=['state', 'year', 'period', 'value'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectively Importing Rows\n",
    "\n",
    "The default behaviour is to import any row from the file that contains text. This is not always what we want.\n",
    "\n",
    "For example:\n",
    "* sometimes a file contains a header or footer full of unneccesary text\n",
    "* the whole data set may not fit into the computer's memory\n",
    "* we only need certain data for our analysis\n",
    "\n",
    "we can use some of `read_csv`'s functionaliy to help out here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can read in the first 20 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                usecols=['state', 'year', 'period', 'value'],\n",
    "                nrows=20)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can skip the earliest year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                usecols=['state', 'year', 'period', 'value'],\n",
    "                skipfooter=12)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can skip the most recent year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                names=['state', 'year', 'period', 'value'],\n",
    "                index_col=False,\n",
    "                skiprows=13)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "\n",
    "1. Read in the file `data/bls-employment-state/LAUST010000000000006.csv`, as `df2`\n",
    "2. Read in the file `data/bls-employment-state/LAUST010000000000003.csv`, as `df3`, but only the years around the financial crisis, 2007-2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Index\n",
    "\n",
    "Notice how in `df`, pandas created a new index for us? We may want to set an index ourselves.\n",
    "\n",
    "Let's do this, first by importing only the 2016 data for Alabama, and using the month as our index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2016 = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                usecols =['period', 'value'],\n",
    "                index_col = ['period'],\n",
    "                nrows=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also have a 'multi-index' structure, where mutliple rows define the index. For example we can import the years 2015 and 2016 data as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent = pd.read_csv('data/bls-employment-state/LAUST010000000000005.csv',\n",
    "                usecols =['year', 'period', 'value'],\n",
    "                index_col = ['period', 'year'],\n",
    "                nrows=24)\n",
    "df_recent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge:\n",
    "Read in the file data/bls-employment-state/LAUST010000000000003.csv, as df3, but only the years around the financial crisis, 2007-2010. Set the index to consist of the state-month-year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now covered the basics for importing data. If you want to know (much!) more, consult the documentation at http://pandas.pydata.org/pandas-docs/version/0.20/generated/pandas.read_csv.html#pandas.read_csv. Warning: it's hard to get the hang of reading the pandas documentation, but over time you become accustomed to it.\n",
    "\n",
    "## Exporting Data\n",
    "\n",
    "Now let's turn to exporting data. We created the DataFrame `df_2016`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to export that data and save it to our project. The function `to_csv()` will do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2016.to_csv('out_data/alabama_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that pandas did as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head out_data/alabama_2016.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many options for the `to_csv()` function - many of which I don't find that useful. One I sometimes use is to change the column separator. Let's change to '&' separators when we write `df_recent` to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent.to_csv('out_data/alabama_recent.csv', sep='&')\n",
    "!head out_data/alabama_recent.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "1. Take your financial crisis data, and write it to file. Use tab separators ('t').\n",
    "2. Reload your financial crisis data under the name 'df_financialCrisis' using `read_csv()`. What did you have to change to make the data import successful?  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
